# Python

## <a name="import">Импорт библиотек</a>

`import pandas as pd`
> импортирует библиотеку для работы с таблицами и данными в виде датафреймов

`import numpy as np`
> импортирует библиотеку для работы с числами

`import seaborn as sns`
> импортирует библиотеку для создания графиков и визуализации данных

`import matplotlib.pyplot as plt`
> импортирует библиотеку для создания графиков и визуализации данных

`import plotly.express as px`
> импортирует библиотеку для создания интерактивных графиков

`import datetime`
> импортирует модуль для работы с датами и временем

`import matplotlib.dates as mdates`
> импортирует модуль для работы с датами и временем в библиотеке matplotlib

`import random`
> импортирует модуль для генерации случайных чисел

`import re`
> импортирует модуль для работы с регулярными выражениями

`import vk_ip`
> импортирует модуль для работы с IP-адресами ВКонтакте

`import os`
> импортирует модуль для работы с операционной системой

`import json as json`
> импортирует модуль для работы с JSON-данными

`import requests`
> импортирует модуль для работы с HTTP-запросами

`import gspread`
> импортирует библиотеку для работы с Google Sheets

`import zipfile`
> импортирует модуль, который предоставляет функции для работы с архивами ZIP в Python

`from io import BytesIO`
> импортирует модуль для работы с бинарными данными в памяти

`import pandahouse as ph`
> импортирует библиотеку для работы с ClickHouse

`from scipy import stats`
> импортирует модуль для статистических вычислений

`from scipy.stats import zscore`
> импортирует функцию для вычисления z-оценки

`import pingouin as pg`
> предоставляет различные функции для статистического анализа данных, включая ANOVA, корреляцию, регрессию и др.

`from scipy.special import comb`
> функция comb из библиотеки scipy.special, которая используется для вычисления комбинаторных коэффициентов

`import statistics`
> библиотека, которая содержит набор функций для выполнения статистических расчетов

`from statsmodels.formula.api import ols`
> интерфейс для моделирования линейной регрессии с помощью формул

`from statsmodels.stats.anova import anova_lm`
> используется для проведения анализа дисперсии (ANOVA) в статистическом анализе данных

`import statsmodels.formula.api as smf`
> работа с формулами и моделями

`import statsmodels.api as sm`
> предоставляет классы и функции для моделирования и статистического анализа данных

`from sklearn.cluster import AgglomerativeClustering`
> используется для кластеризации данных с помощью иерархической кластеризации

`import bootstrapped.bootstrap as bs`<br>`import bootstrapped.stats_functions as bs_stats`
> позволяют оценить распределение статистических показателей, таких как среднее значение, медиана, стандартное отклонение и т.д.

`from statsmodels.stats.contingency_tables import StratifiedTable`
> используется для анализа таблиц сопряженности

`from scipy.stats import chi2_contingency`
> используется для расчета критерия хи-квадрат для таблиц сопряженности

`from df2gspread import df2gspread as d2g`
> функция используется для экспорта данных из pandas DataFrame в Google Sheets

`from oauth2client.service_account import ServiceAccountCredentials`
> используется для аутентификации в Google API с помощью учетных данных службы

`from my_module import my_function`
> содержит функцию или библиотеку функций, специфичных для проекта, над которым работает конкретный автор

## <a name="file">Файловая система, импорт/экспорт данных</a>

### Файловая система

`[x[0] for x in os.walk('my_directory')]`
> выводит список всех папок внутри папки 'my_directory' (включая подпапки)

### Импорт данных

`df = pd.read_csv('C:\\temp\\example.csv')`<br><br>
`df2 = pd.read_csv('C:\\temp\\example2.csv', parse_dates=['date'],  sep=';', dayfirst=True)`
> импорт с локального диска и сохранение файла в датафрейм, во втором примере указан парсинг дат, указан разделитель и формат времени dd/mm/yyyy

`connection_default = {'host': 'link',`<br>
`'database':'default',`<br>
`'user':'******',`<br>
`'password':'******'`<br>
`}`<br>

`q =`<br> 
```
    '''
    SELECT *
    FROM
        {db}.table
    WHERE
        id != 'none'
    ''' 
```
`df = ph.read_clickhouse(query=q, connection=connection_default)`
> SQL запрос в Python через CLICKHOUSE в пандас (нужно подставить link, заменить звездочки учетными данными, верно указать базу данных и написать корректный запрос)

`df = pd.read_csv('C:\\temp\\data.csv.zip',  compression='zip')`<br><br>
`with zipfile.ZipFile('C:\\temp\\data2.csv.zip') as myzip:`<br>
    `with myzip.open('data2.csv') as myfile:`<br>
        `df2 = pd.read_csv(myfile, encoding='ISO-8859-1')`
> импорт в датасет csv файла, а во втором случае импорт конкретного csv файла в архиве

`df = np.genfromtxt('C:\\temp\\data.txt', dtype=None)`<br>
`pd.DataFrame(df)`
> загружает данные из txt файла в виде массива numpy и создает датасет с этими данными

`df = pd.read_excel('C:\\temp\\data.xls')`
> загружает данные из excel файла в виде массива numpy и создает датасет с этими данными

`df = pd.read_csv('link', sep=";")`
> загружает файл csv по ссылке

`def download(link, df):`<br>
    `   base_url = 'link'`<br>
    `   final_url = base_url + urlencode(dict(public_key=link))`<br>
    `   response = requests.get(final_url)`<br>
    `   download_url_file = response.json()['href']`<br>
    `   file_df = pd.read_csv(download_url_file)`<br>
    `   pattern = r'[;,|\t]'`<br>
    `   pattern_test = re.search(pattern, file_df.columns[0])`<br>
    `   if pattern_test is not None:`<br>
        `       sep = pattern_test[0]`<br>
        `       file_df = pd.read_csv(download_url_file, delimiter=None, sep=sep, parse_dates=True)`<br>
    `   globals()[df] = file_df`
> функция для загрузки файлов с ЯндексДиска (заполнить link)

### Экспорт данных

`filename = 'C:\\temp\\data.csv'<br>
`df.to_csv(filename)`
> сохраняет датасет в csv файл

## <a name="string">Работа со строками</a>

`S1 + S2` 
>сложение строк

`S * 3`
повторение строки три раза

`S[i]`
> обращение по индексу символа в строке

`S[i:j:step]`
> позволяет выбрать срез последовательности элементов начиная с индекса i и заканчивая индексом j-1 с заданным шагом step

`len(S)`
> выводит длину строки

`S.find(str, [start],[end])`
> возвращает индекс первого символа первого вхождения str в S или -1, если подстрока не найдена.
> start является необязательным и указывает индекс, с которого нужно начать поиск подстроки. Если start не указан, поиск начинается с начала строки
> end также является необязательным и указывает индекс, до которого нужно искать подстроку. Если end не указан, поиск производится до конца строки

`S.rfind(str, [start],[end])`
> то же что и предыдущее, но возвращает номер последнего вхождения или -1

`S.index(str, [start],[end])`
> аналогично S.find, отличие в том, что если подстрока не найдена, S.index() генерирует исключение ValueError

`S.rindex(str, [start],[end])`
> то же что и предыдущее, но возвращает номер последнего вхождения или ValueError

`S.replace(шаблон, замена)`
> замена символов в строке по шаблону

`S.split(символ)`
> разбиение строки по разделителю, указанному в скобках

`S.isdigit()`
> cостоит ли строка из цифр - возвращает true или false

`S.isalpha()`
> cостоит ли строка из букв - возвращает true или false

`S.isalnum()`
> cостоит ли строка из цифр или букв - возвращает true или false

`S.islower()`
> cостоит ли строка из символов в нижнем регистре - возвращает true или false

`S.isupper()`
>cостоит ли строка из символов в верхнем регистре - возвращает true или false

`S.isspace()`
> cостоит ли строка из неотображаемых символов: пробел, перевод страницы новая строка и т.д. - возвращает true или false

`S.istitle()`
> начинаются ли слова в строке с заглавной буквы - возвращает true или false

`S.upper()`
> преобразовывает строку к верхнему регистру

`S.lower()`
> преобразовывает строку к нижнему регистру

`S.startswith(шаблон)`
> начинается ли строка с шаблона - возвращает true или false

`S.endswith(шаблон)`
> заканчивается ли строка шаблоном - возвращает true или false

`S.join(список)`
> объединяет элементы списка в одну строку S, используя строку S в качестве разделителя между элементами списка

`ord(символ)`
> возвращает код символа в таблице символов ASCII

`chr(число)`
> возвращает символ, соответствующий переданному числу в кодировке Unicode

`S.capitalize()`
> переводит первый символ строки в верхний регистр, а все остальные в нижний

`S.center(width, [fill])`
> выравнивает строку S по центру, путем добавления символов fill (если указано) слева и справа от строки до достижения заданной ширины (width)

`S.count(str, [start],[end])`
> возвращает количество непересекающихся вхождений подстроки в диапазоне [start, end]

`S.expandtabs([tabsize])`
> возвращает копию строки, в которой все символы табуляции заменяются одним или несколькими пробелами. Если TabSize не указан, табуляция полагается равным 8 пробелам

`S.lstrip([chars])`
> удаление пробельных символов в начале строки

`S.rstrip([chars])`
> удаление пробельных символов в конце строки

`S.strip([chars])`
> удаление пробельных символов в начале и в конце строки

`S.partition(шаблон)`
> возвращает кортеж из трех элементов: 1й будет содержать часть строки S, которая находится перед первым вхождением шаблона; 2й элемент будет содержать сам шаблон; 3й элемент будет содержать часть строки S, которая находится после первого вхождения шаблона

`S.rpartition(sep)`
> то же самое, что и предыдущая команда, но выполняется в обратном направлении

`S.swapcase()`
> переводит символы нижнего регистра в верхний, а верхнего – в нижний

`S.title()`
> первую букву каждого слова переводит в верхний регистр, а все остальные в нижний

`S.zfill(width)`
> используется для добавления ведущих нулей в строку S до заданной ширины width

`S.ljust(width, fillchar=" ")`
> то же самое, что и предыдущая команда, но заполняет символом fillchar

`S.rjust(width, fillchar=" ")`
> то же самое, что и предыдущая команда, но заполняет символом fillchar и выполняется в обратном направлении

## <a name="list">Работа со списками</a>

`append()`
> добавляет в конец списка один новый элемент

`extend()`
> расширяет список другим списком

`insert(index, value)`
> позволяет вставлять значение в список в заданной позиции

`index()`
> возвращает индекс первого элемента, значение которого равняется переданному в метод значению

`remove()`
> удаляет первый элемент, значение которого равняется переданному в метод значению

`pop(index)`
> удаляет элемент по указанному индексу и возвращает его

`reverse()`
> меняет на противоположный порядок следования значений в списке

`len(list)`
> выводит количество элементов списка

`sum(list)`
> выводит сумму элементов в списке

`count()`
> возвращает количество элементов в списке, значения которых равны переданному в метод значению

`clear()`
> удаляет все элементы из списка

`copy()`
> создает поверхностную копию списка

`sort()`
> сортирует список, для обратного порядка указать reverse

### Списочные выражения

Дано:<br>
`word = 'test'`<br>
`numbers = [1, 5, 10, 25, 50]`<br>
`words = ['house', 'worm', 'sex']`<br>
`str_numbers` = '12345'`<br>
`mix = [1, 'house', 3.45]`

тогда:

| Выражение | Суть | Результат |
| ----------|------|-----------|
| [0 for i in range(10)]| создает список, содержащий определенное количество заданных элементов | [0, 0, 0, 0, 0] |
| [int(i) for i in str_numbers] | преобразует список строк из чисел в список целых чисел | [1, 2, 3, 4, 5] |
| [i ** 3 for i in range(1, 5)] | list comprehension, которое в данном случае генерит список кубов чисел in range | [1, 8, 27, 64] |
| [i for i in numbers if i != 10] | удаляет элементы из списка по условию | [1, 5, 25, 50] |
| [i * 2 for i in numbers]| создаст список, в котором каждый элемент "numbers" будет умножен на 2 | [2, 10, 20, 50, 100] |
|len([item for item in numbers if item > 5]) | вычисляет количество элементов списка numbers, которые больше 5 | 3 |
| [w * 2 for w in word] | создаст список с удвоенными значениями элементов word | ['tt', 'ee', 'ss', 'tt'] |
| [l[0] for l in words] | создаст список, содержащий первый элемент от каждого элемента списка words | ['h', 'w', 's'] |
| all(numbers[i] <= numbers[i+1] for i in range(len(numbers)-1)) | проверяет условие, что каждый последующий элемент списка "numbers" не меньше предыдущего элемента | True |
| [i for i in numbers if i < 15] | вернет список с элементами списка "numbers", которые меньше 15 | [1, 5, 10] |
| [l[0] for l in words if len(l) == 3] | вернет список из первых элементов каждого элемента списка words, длина которого равна 3 | ['s'] |

### Прочие методы

Дано:<br>
`word = 'test'`<br>
`numbers = [1, 5, 10, 25, 50]`<br>
`words = ['house', 'worm', 'sex']`<br>
`str_numbers` = '12345'`<br>
`mix = [1, 'house', 3.45]`

`for num, word in zip(numbers, words):`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`print(f"{num} {word}")`<br>
`1 house`<br>
`5 worm`<br>
`10 sex`<br>
> использована функция zip() для создания итератора, который позволяет проходить по двум спискам одновременно

`result = 1`<br>
`for i in range(0,len(numbers)):`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`result = result * numbers[i]`<br>
`print(result)`<br>
`62500`
> перемножает все числа в списке "numbers" по очереди и сохраняет результат в переменной "result"

`print(list(map(type, mix)))`<br>
`[<class 'int'>, <class 'str'>, <class 'float'>]`
> выведет список, содержащий тип каждого элемента списка

`if len(set(numbers)) == 1:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`print('YES')`<br>
`else:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`print('NO')`<br>
`NO`<br>
> код проверяет, все ли элементы списка numbers равны между собой

`n = int(input())`<br>
`counter = []`<br>
`while n != 0:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`last_digit = n % 10`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`n = n // 10`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`counter.append(last_digit)`<br>
`counter.reverse()`<br>
`print(counter)`<br>
> выводит список цифр введенного пользователем числа в порядке от первой цифры до последней, и для числа 456 результатом будет [4, 5, 6]

## <a name="pandas">Работа с датафреймами (Pandas / NumPy)</a>


`df = pd.DataFrame()`
> cоздает пустой датафрейм

`df = df.reset_index()`
> возвращает датафрейм с новым индексом, начинающимся с 0, и старым индексом, сохраненным в виде нового столбца

`df.isna().sum()`
> возвращает количество пропущенных значений в каждом столбце

`df.columns = [x.lower() for x in df.columns]`
> приводит все названия столбцов к нижнему регистру

`df = df.rename(columns={'x': 'name', 'y': 'new_name'})`
> переименовывает столбец в датасете

`df = df.rename(columns={df.columns[0]:"new_column_name"})`
> переименовывает столбец в датасете по индексу

`df.columns = df.columns.str.replace('[.]', '_').str.replace('[ ]', '').lower()`
> переименовывает столбец в датасете, удаляя "лишние" символы и переводит к нижнему регистру

`df = df.drop(['column_1','column_2'], axis=1)`
`df = df.loc[:,('column_1', 'column_4', 'column_7')]`
`df = df.drop(columns=df.columns[0])`
> удаление столбцов в датасете:<br> первый - удаляет указанные столбцы;<br> второй - удаляет все столбцы, кроме указанных;<br> третий - удаляет столбцы по индексу

`df['numbers'] = df['numbers'].astype(int)`<br>
`df = df.apply(lambda x: pd.to_numeric(x, errors='coerce')).dropna()`
> первый код переводит текстовые значения в целые числа,<br>
> второй код позволяет также удалить все строки с некорректными или отсутствующими значениями - оставить только строки с числовыми значениями

`len(df.loc[df.assign_type != df.reserved_type])`
> позволяет вывести количество строк не соответствующих строкам другого столбца

`df.groupby('year').month.agg(pd.Series.mode)`
> группирует строки по году и для каждой группы найдет моду (самое часто встречающееся значение), в данном случае, месяца

`df = df.astype({"a": int, "b": complex})`
> меняет типы данных в столбцах

`df['column'].tolist()`
> переводит cтолбец колонки в список

`df = df['column'] + '\\' + df['column_2']`
> делает из содержимого двух колонок третью

`df = df.assign(new_column = df.column_1 * df.column_2)`
> cоздает столбец на основании математической операции между двумя столбцами

`orders.isna().sum()`
> выводит информацию по пропущенным значениям в датасете

`df.groupby('column_1').agg({'success': 'sum'})`
> группирует датафрейм по количество успешных операций для столбца column_1

`df = df.unstack('column_1')`
> преобразует иерархически индексированный датасет, добавляя колонки из уровня, соответствующего указанной колонке, на новый уровень колонок

`df2 = pd.wide_to_long(df, ['column_1', 'column_2'], i=['type', 'name'], j='year', sep='_')`
> создает новый датасет, в котором идентификаторы (в данном случае, type, name) хранятся в отдельных столбцах, а значения из исходных столбцов с годами (year) и значениями (column_1, column_2) хранятся в отдельных строках

`df2 = df.explode('Column_1')`
> создает новый датасет, в котором каждый элемент списка в столбце 'Column_1' разбивается на отдельную строку, а значения в остальных столбцах дублируются соответственно

`df.groupby('column_1').agg({'column_2': 'sum'})`
> группирует строки в датасете df по уникальным значениям в столбце "column_1" и для каждой группы вычисляет сумму значений в столбце "column_2". Результатом будет новый датасет с одним индексом "column_1" и одним столбцом "column_2", содержащим сумму значений "column_2" для каждого уникального значения "column_1"

`df.sort_values('column_2', ascending=False)`
> сортирует датасет df по столбцу column_2 в порядке убывания (от наибольшего значения к наименьшему)

`df['name'].value_counts()`
> используется для подсчета количества уникальных значений в столбце "name" датасета df и создания объекта типа Series с количеством вхождений каждого уникального значения

`df.query("name == 'John' and surname == 'Doe'")`
> выбирает в датасете df все строки, где значение столбца "name" равно "John" и значение столбца "surname" равно "Doe"

#### Описательная статистика датасетов

`df.info()`
>  позволяет получить общую информацию о датасете, такую как количество строк, количество столбцов, их имена и типы данных, количество ненулевых значений в каждом столбце и использованную память

`df.groupby(['name', 'age']).agg({'income': 'describe'})`
> вычисляет основные статистические показатели для каждой группы значений столбца income, включая количество наблюдений (count), среднее значение (mean), стандартное отклонение (std), минимальное и максимальное значения (min и max) и квартили (25%, 50%, 75%)

`df.describe(include='object')`<br>
`df.describe(include='datetime')`
> первый используется для получения статистической информации о колонках в объекте Pandas DataFrame, содержащих данные типа "object", второй для для колонок даты и времени

## <a name="statistics">Статистические методы в Python</a>

> Для исполнения кодов раздела необходимо импортировать библиотеки/модули:<br>
> statistics, numpy;<br>
> stats from scipy;<br>
> normaltest, shapiro, normaltest, levene, bartlett, norm, ttest_ind from scipy.stats
> math

#### Меры центральной тенденции

###### Мода

`data = [1, 2, 2, 3, 4, 4, 4]`<br>
`print("Мода: ", statistics.mode(data))`<br>
`Мода:  4`<br>
> Мода - это значение в наборе данных, которое встречается наиболее часто

###### Среднее

`data = [1, 2, 2, 3, 4, 4, 4]`<br>
`print("Среднее: ", statistics.mean(data))`<br>
`Среднее:  2.857142857142857`<br>
> Среднее значение, также известное как среднее арифметическое, вычисляется путем сложения всех значений в наборе данных и деления полученной суммы на количество значений в наборе<br>
> $$\bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i$$<br>
> где $\bar{x}$ обозначает среднее значение, $n$ - количество элементов в выборке, а $x_1, x_2, ..., x_n$ - значения элементов выборки. Формула использует знак суммы $\sum$, который означает суммирование всех значений $x$ в выборке.

###### Медиана

`data = [1, 2, 2, 3, 4, 4, 4]`<br>
`print("Медиана: ", statistics.median(data))`<br>
`Медиана:  3`<br>
> Значение, которое разделяет упорядоченный набор данных на две равные половины
> Формула для расчета с четным числом элементов выборки:
> $$median=\frac{x_{\frac{n}{2}} + x_{\frac{n}{2}+1}}{2}$$
> где где $n$ - количество элементов в выборке, $x_{\frac{n}{2}}$ - значение элемента с индексом $\frac{n}{2}$ и $x_{\frac{n}{2}+1}$ - значение элемента с индексом $\frac{n}{2}+1$
> Формула для расчета с нечетным числом элементов выборки:
> $$median = x_{\frac{n+1}{2}}$$
> где $x$ - массив элементов, а $n$ - число элементов в массиве

###### Межквартильный размах

`data = np.array([12, 15, 16, 18, 19, 20, 22, 25, 28, 31, 35])`<br>
`Q1 = np.percentile(data, 25, interpolation='midpoint')`<br>
`Q3 = np.percentile(data, 75, interpolation='midpoint')`<br>
`IQR = Q3 - Q1`<br>
`print("Межквартильный размах:", IQR)`<br>
`Межквартильный размах: 9.5`
> Межквартильный размах - определяется как разница между верхним и нижним квартилями в наборе данных.
> Квартили - это значения, которые разделяют упорядоченный набор данных на четыре равные части. Верхний квартиль (Q3) - это значение, которое делит верхние 25% данных от нижних 75%, а нижний квартиль (Q1) - это значение, которое делит нижние 25% данных от верхних 75%.
> Таким образом, межквартильный размах (IQR) - это разница между Q3 и Q1. Он представляет собой интерквартильный диапазон, который содержит 50% данных и позволяет оценить разброс значений в наборе данных, игнорируя выбросы

#### Меры изменчивости

###### Дисперсия

`data = [1, 5, 2, 7, 1, 9, 3, 8, 5, 9]`<br>
`print("Дисперсия: ", statistics.variance(data))`<br>
`Дисперсия:  10`
> Дисперсия - это среднее арифметическое квадратов отклонений каждого элемента выборки от ее среднего значения. Она измеряет, насколько значения в выборке отклоняются от ее среднего значения и показывает, как распределены значения вокруг среднего значения. Дисперсия выражается в квадратных единицах измерения выборки
> $$s^2 = \frac{1}{n-1}\sum_{i=1}^{n}(x_i - \bar{x})^2$$
> где $s^2$ - выборочная дисперсия, $n$ - размер выборки, $x_i$ - i-й элемент выборки, $\bar{x}$ - выборочное среднее.

###### Стандартное отклонение

`data = [1, 5, 2, 7, 1, 9, 3, 8, 5, 9]`<br>
`print("Стандартное отклонение: ", statistics.stdev(data))`<br>
`Стандартное отклонение:  3.1622776601683795`
> Стандартное отклонение - это квадратный корень из дисперсии выборки. Оно измеряет степень разброса данных относительно их среднего значения и представляет собой стандартную меру распределения выборки. Стандартное отклонение может быть выражено в тех же единицах измерения, что и сама выборка.
> Таким образом, стандартное отклонение и дисперсия оба показывают, насколько значения в выборке отклоняются от ее среднего значения, но стандартное отклонение также показывает, как распределены значения вокруг среднего значения.
> $$\sigma = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (x_i - \bar{x})^2}$$
> где $N$ - количество значений, $x_i$ - i-е значение, а $\bar{x}$ - среднее значение

###### Среднеквадратическое отклонение
`data = [1, 5, 2, 7, 1, 9, 3, 8, 5, 9]`<br>
`mean_value = statistics.mean(data)`<br>
`print("Среднеквадратическое отклонение: ", statistics.stdev(data, xbar=mean_value))`<br>
`Среднеквадратическое отклонение:  3.1622776601683795`
> Среднеквадратическое отклонение - это корень из среднего арифметического квадратов отклонений каждого элемента выборки от ее среднего значения. Оно также измеряет степень разброса данных относительно их среднего значения и представляет собой стандартную меру распределения выборки. Среднеквадратическое отклонение может быть выражено в тех же единицах измерения, что и сама выборка.
> $$\sigma = \sqrt{\frac{1}{N}\sum_{i=1}^{N}(x_i - \mu)^2}$$
> где $N$ - количество элементов в выборке, $x_i$ - i-й элемент выборки, а $\mu$ - среднее значение выборки

###### Стандартная ошибка среднего
`variance = 4`<br>
`n = 100`<br>
`SEM = math.sqrt(variance/n)`<br>
`print("SEM:", SEM)`<br>
`SEM: 0.2`
> Стандартная ошибка среднего - мера разброса среднего значения в выборке относительно среднего значения в генеральной совокупности, это среднеквадратическое отклонение распределения выборочных средних
> $$SE = \frac{s}{\sqrt{n}}$$
> где $s$ - стандартное отклонение выборки, $n$ - размер выборки

#### Z-преобразование (стандартизация)

###### Для генеральной совокупности
`data = np.array([12, 15, 16, 18, 19, 20, 22, 25, 28, 31, 35])`<br>
`mean = np.mean(data)`<br>
`std = np.std(data)`<br>
`z_data = stats.zscore(data)`<br>
`print('Z-преобразованные данные:', z_data)`<br>
`Z-преобразованные данные: [-1.45683394 -1.01577412 -0.86875418 -0.57471431 -0.42769437 -0.28067443
  0.01336545  0.45442527  0.89548508  1.3365449   1.92462466]`
  > Z-преобразование - это процесс стандартизации набора данных путем вычитания среднего значения и деления на стандартное отклонение. Если результат z-преобразования равен 0, то это означает, что значение переменной равно ее среднему значению. Если результат равен 1, то это означает, что значение переменной отклоняется от ее среднего значения на одно стандартное отклонение
  > $$Z = \frac{x - \mu}{\sigma}$$
  > где - $x$ - наблюдаемое значение, $\mu$ - среднее значение распределения, $\sigma$ - стандартное отклонение распределения

###### Для выборки из генеральной совокупности
`all_data = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])`<br>
`sample = np.random.choice(all_data, size=5, replace=False)`<br>
`sample_mean = np.mean(sample)`<br>
`sample_std = np.std(sample, ddof=1)`<br>
`z_sample = (sample - sample_mean) / sample_std`<br>
`print('Z-преобразованная выборка:', z_sample)`<br>
`Z-преобразованная выборка: [-1.19571306 -0.15596257  1.14372554  0.88378792 -0.67583782]`
> для применения z-преобразования к выборке необходимо вычислить выборочное среднее значение и выборочное стандартное отклонение
> $$Z = \frac{\bar{x} - \mu}{\frac{\sigma}{\sqrt{n}}}$$
> где $\bar{x}$ - выборочное среднее, $\mu$ - среднее значение генеральной совокупности, $\sigma$ - стандартное отклонение генеральной совокупности, а $n$ - размер выборки

###### Для отдельного наблюдения из выборки
`sample = np.array([4, 5, 6, 7, 8, 9, 10])`<br>
`sample_mean = np.mean(sample)`<br>
`sample_std = np.std(sample, ddof=1)`<br>
`z_sample = (sample[4] - sample_mean) / sample_std`<br>
`print('Отдельно взятое наблюдение выборки:', sample[4])`<br>
`print('Z-значение для отдельно взятого наблюдения:', z_sample)`<br>
`Отдельно взятое наблюдение выборки: 8`<br>
`Z-значение для отдельно взятого наблюдения: 0.4629100498862757`<br>
> $$z = \frac{x - \mu}{\sigma}$$
> где $x$ - значение в выборке, $\mu$ - среднее значение выборки, $\sigma$ - стандартное отклонение выборки

#### Проверка распределения на нормальность

> ни один из этих тестов не гарантирует, что данные точно имеют нормальное распределение. Они только дают представление о том, насколько близки данные к нормальному распределению

###### Тест Шапиро-Уилка

`data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]`<br>
`stat, p = shapiro(data)`<br>
`print('Statistics=%.3f, p=%.3f' % (stat, p))`<br>
`alpha = 0.05`<br>
`if p > alpha:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`print('Распределение похоже на нормальное (не отвергаем H0)')`<br>
`else:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`print('Распределение не похоже на нормальное (отвергаем H0)')`<br>
`Statistics=0.970, p=0.892`<br>
`Распределение похоже на нормальное (не отвергаем H0)`
> Тест Шапиро-Уилка является более чувствительным к отклонениям от нормальности, особенно в случаях, когда данные имеют ярко выраженные выбросы. Он также более точен при малых выборках. Однако, он может оказаться менее мощным в случае, когда выборка слишком большая

###### Тест хи-квадрат

`data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]`<br>
`stat, p = normaltest(data)`<br>
`print('Statistics=%.3f, p=%.3f' % (stat, p))`<br>
`alpha = 0.05`<br>
`if p > alpha:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`print('Распределение похоже на нормальное (не отвергаем H0)')`<br>
`else:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`print('Распределение не похоже на нормальное (отвергаем H0)')`<br>
`Statistics=2.027, p=0.363`<br>
`Распределение похоже на нормальное (не отвергаем H0)`
> Тест хи-квадрат может быть более устойчивым в случае, когда данные более-менее нормальные, но не слишком точны. Также, он может быть полезен, когда нам интересно не только проверить, нормальные ли данные, но и определить, насколько сильно они отклоняются от нормальности

#### Проверка гомогенности дисперсий

###### Тест Левена

`data = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]`<br>
`statistic, pvalue = levene(*data)`<br>
`if pvalue > 0.05:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`print(f"p-value = {pvalue}. Гомогенность дисперсий присутствует")`<br>
`else:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`print(f"p-value = {pvalue}. Гомогенность дисперсий отсутствует")`<br>
`p-value = 1.0. Гомогенность дисперсий присутствует`
> Тест основан на сравнении среднеквадратических отклонений (MSE) в группах. Он менее чувствителен к выбросам, чем тест Бартлетта, так как MSE рассчитывается на основе медианы, а не на основе среднего значения. Он предполагает нормальность распределения в каждой группе. Если распределение не является нормальным, то тест Левена может давать неправильные результаты
> $$W=\frac{(N-k) \sum_{i=1}^{k}\left(n_{i}\left(Z_{i}-\overline{Z}\right)^{2}\right)}{(k-1) \sum_{i=1}^{N}\left(Y_{i}-\overline{Y}\right)^{2}}$$
> где $W$ - статистика теста Левена, $N$ - общее число наблюдений, $k$ - количество групп, $n_i$ - размер $i$-й группы, $Z_i$ - среднее значение $i$-й группы, $\overline{Z}$ - общее среднее значение всех групп, $Y_i$ - каждое наблюдение в $i$-й группе, $\overline{Y}$ - общее среднее значение всех наблюдений

###### Тест Бартлетта

`group1 = [1, 2, 3, 4, 5]`<br>
`group2 = [2, 4, 6, 8, 10]`<br>
`stat, p = bartlett(group1, group2)`<br>
`if p < 0.05:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`result = 'Отвергаем гипотезу о гомогенности дисперсий'`<br>
`else:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`result = 'Не отвергаем гипотезу о гомогенности дисперсий'`<br>
`print(f'Тест Бартлетта: статистика = {stat:.3f}, p-значение = {p:.3f}. {result}')`<br>
`Тест Бартлетта: статистика = 1.587, p-значение = 0.208. Не отвергаем гипотезу о гомогенности дисперсий`
> Тест основан на сравнении дисперсий в группах. Он более чувствителен к выбросам, чем тест Левена, так как рассчитывает статистику на основе среднего значения, а не на основе медианы. Он предполагает нормальность распределения в каждой группе. Если распределение не является нормальным, то тест Бартлетта может давать неправильные результаты
> $$B = \frac{(N-1)\sum_{i=1}^k n_i \ln(s_i^2) - N \ln(s_p^2)}{1 + \frac{1}{3(k-1)}\left(\sum_{i=1}^k \frac{1}{n_i} - \frac{1}{N}\right)}$$
> где $N$ - общее количество наблюдений, $k$ - количество групп, $n_i$ - количество наблюдений в $i$-й группе, $s_i^2$ - выборочная дисперсия $i$-й группы, $s_p^2$ - средняя выборочная дисперсия всех групп

#### Определение доверительных интервалов

`n = 30          # размер выборки`<br>
`x_bar = 7.5     # выборочное среднее`<br>
`alpha = 0.05    # уровень доверия`<br>
`# известное стандартное отклонение генеральной совокупности`<br>
`sigma = 2.5`<br>
`# находим значение квантиля распределения`<br>
`z = norm.ppf(1 - alpha/2)`<br>
`# вычисляем границы доверительного интервала`<br>
`lower = x_bar - z * sigma / math.sqrt(n)`<br>
`upper = x_bar + z * sigma / math.sqrt(n)`<br>
`print(f'Доверительный интервал: [{lower:.3f}, {upper:.3f}]')`<br>
`Доверительный интервал: [6.605, 8.395]`
> Доверительный интервал - это диапазон значений, в котором находится неизвестный параметр генеральной совокупности с известным уровнем доверия
> $$\bar{x} \pm z_{\alpha/2} \cdot \frac{\sigma}{\sqrt{n}}$$
> где $\bar{x}$ - выборочное среднее, $z_{\alpha/2}$ - критическое значение стандартного нормального распределения, соответствующее уровню доверия $\alpha$, $\sigma$ - известное стандартное отклонение, $n$ - размер выборки

###### Основываясь на знании t - распределения

`# устанавливаем уровень доверия`<br>
`confidence_level = 0.95`<br>
`# задаем количество степеней свободы`<br>
`degrees_of_freedom = 19`<br>
`# вычисляем критическое значение t-статистики`<br>
`t_critical = stats.t.ppf((1 + confidence_level) / 2, degrees_of_freedom)`<br>
`# задаем значения стандартного отклонения, размера выборки и стандартной ошибки среднего`<br>
`sd = 11.3`<br>
`n = 20`<br>
`standard_error = sd / np.sqrt(n)`<br>
`# задаем выборочное среднее и предельную ошибку`<br>
`sample_mean = 89.9`<br>
`margin_of_error = t_critical * standard_error`<br>
`# рассчитываем доверительный интервал`<br>
`confidence_interval = (sample_mean - margin_of_error, sample_mean + margin_of_error)`<br>
`print("Доверительный интервал для t - распределения: ", confidence_interval)`<br>
`Доверительный интервал для t - распределения:  (84.61143720745503, 95.18856279254499)`
> $$CI = \bar{x} \pm t_{\frac{\alpha}{2},n-1}\frac{s}{\sqrt{n}}$$
> где $\bar{x}$ - среднее значение выборки, $t_{\frac{\alpha}{2},n-1}$ - критическое значение t-распределения с $\frac{\alpha}{2}$ уровнем значимости и $n-1$ степенями свободы (где $\alpha$ - уровень значимости), $s$ - стандартное отклонение выборки, $n$ - размер выборки

#### Статистические тесты

###### двухвыборочный t-критерий Стьюдента

`group1 = [3, 5, 7, 9, 11]`<br>
`group2 = [2, 4, 6, 8, 10]`<br>
`# вычисляем средние значения`<br>
`mean1 = sum(group1) / len(group1)`<br>
`mean2 = sum(group2) / len(group2)`<br>
`# вычисляем стандартные отклонения`<br>
`std1 = stats.tstd(group1)`<br>
`std2 = stats.tstd(group2)`<br>
`# вычисляем t-статистику`<br>
`t = (mean1 - mean2) / ((std1 ** 2 / len(group1)) + (std2 ** 2 / len(group2))) ** 0.5`<br>
`# определяем степени свободы`<br>
`df = len(group1) + len(group2) - 2`<br>
`# определяем p-уровень значимости`<br>
`p = stats.t.sf(abs(t), df) * 2`<br>
`# задаем уровень значимости`<br>
`alpha = 0.05`<br>
`if p < alpha:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`print(f"Различия статистически значимы: p={p}")`<br>
`else:`<br>
&nbsp;&nbsp;&nbsp;&nbsp;`print(f"Различия не являются статистически значимыми:p={p}")`<br>
`Различия не являются статистически значимыми:p=0.6305360755569764`
> тест, используемый для проверки значимости различий между двумя выборками. В основе t-критерия лежит понятие t-статистики, которая представляет собой отношение разности между средними значениями двух выборок к их стандартной ошибке. Важным условием применения t-критерия является то, что данные должны быть распределены нормально или близко к нормальному распределению. Если это условие не выполняется, то использование t-критерия может привести к неверным результатам
> $$t = \frac{\overline{X_1} - \overline{X_2}}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}$$
> где $\overline{X_1}$ и $\overline{X_2}$ - выборочные средние первой и второй выборок, $s_p$ - выборочное стандартное отклонение, рассчитанное по объединенным выборкам, $n_1$ и $n_2$ - размерности первой и второй выборок соответственно


